# ğŸ§  Sentiment Classification using RNNs/LSTMs + Attention (IMDB Dataset)

This project implements a modular deep learning pipeline for **sentiment classification** using different RNN architectures and **four attention mechanisms**. All experiments are run on the **IMDB movie review dataset**, comparing Vanilla RNN/LSTM and Bidirectional variants.

---

## ğŸ“ Folder Structure

```
â”œâ”€â”€ attention.py            # All attention mechanism classes
â”œâ”€â”€ models.py               # RNN/LSTM/BiRNN/BiLSTM model definitions
â”œâ”€â”€ dataset.py              # Tokenization, vocab building, and dataloading
â”œâ”€â”€ train.py                # CLI-driven training and evaluation script
â”œâ”€â”€ utils.py                # Metrics, evaluation, attention visualization
â”œâ”€â”€ requirements.txt        # List of dependencies
â”‚
â”œâ”€â”€ raw files/              # Original notebooks and raw development code
â”œâ”€â”€ model params/           # saved model weights
â”œâ”€â”€ report/                 # ğŸ“Š Evaluation JSONs + ğŸ“„ Final Report
â”‚   â”œâ”€â”€ report.pdf
â”‚   â”œâ”€â”€ metrics_*.json
```

---

## ğŸ§  Model Variants

The following 16 combinations were evaluated:

| Model Type    | Attention Mechanism                        |
|---------------|---------------------------------------------|
| Vanilla RNN   | Bahdanau, Luong Dot, Luong General, Concat |
| Vanilla LSTM  | Bahdanau, Luong Dot, Luong General, Concat |
| BiRNN         | Bahdanau, Luong Dot, Luong General, Concat |
| BiLSTM        | Bahdanau, Luong Dot, Luong General, Concat |

You can also run **any model without attention** using `--attention None`.

---

## ğŸš€ How to Run via CLI

Install requirements:

```bash
pip install -r requirements.txt
```

Run training & evaluation:

```bash
python train.py --model BiLSTM --attention Bahdanau
```

To run without attention:

```bash
python train.py --model VanillaRNN --attention None
```

### CLI Arguments

| Argument        | Description                             | Default |
|-----------------|------------------------------------------|---------|
| `--model`       | `VanillaRNN`, `VanillaLSTM`, `BiRNN`, `BiLSTM` | Required |
| `--attention`   | `Bahdanau`, `LuongDot`, `LuongGeneral`, `LuongConcat`, `None` | `None` |
| `--epochs`      | Number of training epochs                | 10      |
| `--batch_size`  | Batch size                               | 32      |
| `--lr`          | Learning rate                            | 1e-3    |

---

## ğŸ“Š Evaluation Metrics

Each combination is evaluated using:

- Accuracy
- Precision
- Recall
- F1 Score
- Confusion Matrix

ğŸ“ All results are saved inside the `report/` folder as:

```
metrics_<Model>_<Attention>.json
```

---

## ğŸ§  Dataset Details

- **Source**: HuggingFace IMDB Dataset
- **Split**: 25,000 training / 25,000 testing
- **Task**: Sequence classification (positive/negative sentiment)
- **Tokenizer**: Custom lowercasing + alphanumeric
- **OOV Handling**: Unknown tokens default to 0
- **Padding**: Max-length based per sample

---

## ğŸ“ Refer to `report/`

The folder contains:

- ğŸ“„ `report.pdf` â†’ Final project report with:
  - Architecture diagrams
  - Evaluation comparison
  - Attention heatmaps
  - Key learnings & challenges

- ğŸ“Š `metrics_*.json` â†’ Evaluation results for each model + attention combo.

---

## âš™ï¸ Requirements

```txt
Refer requirements.txt
```

Install via:

```bash
pip install -r requirements.txt
```

---

## âœ… Features

- Modular model + attention architecture
- CLI support for experimentation
- GPU-compatible (tested on T4 via Kaggle)
- OOV handling in test set
- Attention visualization (bonus)

---

## ğŸ‘¨â€ğŸ’» Author

**Rishit Mittal**  
_IIT Hyderabad | July 2025_

---

## ğŸ“Œ Coming Soon (Planned)

- [ ] Config file support (YAML/JSON)
- [ ] CLI for evaluation only
- [ ] Hyperparameter sweep
